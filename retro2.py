# -*- coding: utf-8 -*-
"""Untitled9.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1KqAKi3YWuF23IU5TF7Yv1e66RwnrXNgJ
"""

#Primero realizamos la importación de lo que vamos a necesitar para poder implementar el algoritmo

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn.datasets import load_iris
from sklearn.metrics import accuracy_score, recall_score, confusion_matrix, ConfusionMatrixDisplay
from sklearn.impute import SimpleImputer
import matplotlib.pyplot as plt

#En esta función main primero realizamos la carga de los datos y dropeamos del conjunto X nuestro target, que en el caso de esta base de datos
#es si un tumor es maligno o benigno segun ciertas características y dejamos a nuestro conjunto Y con esta columna, despues se realizo la manipulacion
#de los datos faltantes ya que si no el algortimo knn no se puede aplicar, asi que en este caso decidi llenar los Nan con la media de la columna simplemente
#para no dejarlos vacios y no eliminarlos tampoco, después ya dividimos nuestros conjuntos en entrenamiento y prueba para después seleccionar el numero de vecinos,
#en esta parte me di cuenta que entre mas vecinos menor accuracy, y al reves, lo cual se debe ah que con pocos vecinos puede haber overfitting y con muchos el modelo
#llega a ser demasiado general, por lo que no logra identificar patrones y por eso se da un accuracy menor. Tambien calculamos el recall donde la principal diferencia
#es que este nos indica las instancias positivas y el accuracy son los datos correctamente predichos, y para terminar esta parte la matriz de confusion donde
#basicamente observamos falsos positivos, negativos, verdaderos positivos, negativos.
#Finalmente creamos el clasificador y entrenamos el modelo, despues se realiza la predicción con los datos de prueba y visualizamos la precisón.

def main():

  data = pd.read_csv('/content/data.csv')

  X = data.drop('diagnosis', axis=1)
  y = data['diagnosis']

  imputer = SimpleImputer(strategy='mean')
  X = imputer.fit_transform(X)


  X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3)

  k = 10
  knn=KNeighborsClassifier(n_neighbors=k)

  knn.fit(X_train,y_train)
  y_pred=knn.predict(X_test)

  accuracy = accuracy_score(y_test,y_pred)
  print(f'Precisión: {accuracy*100:.2f}%')

  recall = recall_score(y_test, y_pred, average='weighted')
  print(f'Recall: {recall*100:.2f}%')

  cm = confusion_matrix(y_test, y_pred)
  print('Matriz de Confusión:')
  print(cm)

  disp = ConfusionMatrixDisplay(confusion_matrix=cm)
  disp.plot(cmap=plt.cm.Blues)
  plt.show()

  plot_knn_performance(X_train, X_test, y_train, y_test)

#Aqui se implemento esta funcion para evaluar el rendimiento del clasfiicador para diferentes k (en este caso de 1 a 10 por poner un numero) y ver como cambia la
#precisón del modelo en función de esta k, y es la gráfica que estamos observando, basicamente como varía la precisión con cada valor de k.

def plot_knn_performance(X_train, X_test, y_train, y_test):
  k_valores = list(range(1, 11))
  accuracies = []

  for k in k_valores:
    knn = KNeighborsClassifier(n_neighbors=k)
    knn.fit(X_train,y_train)
    y_pred = knn.predict(X_test)
    accuracies.append(accuracy_score(y_test, y_pred))

  plt.plot(k_valores, accuracies, marker='o')
  plt.title('K vs Precisión')
  plt.ylabel('Precisión')
  plt.xlabel('Valor de k (vecinos)')
  plt.xticks(k_valores)
  plt.grid(True)
  plt.show()

if __name__ == '__main__':
  main()

